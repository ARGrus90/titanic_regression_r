{"cells":[{"metadata":{"_uuid":"051d70d956493feee0c6d64651c6a088724dca2a","_execution_state":"idle","trusted":true},"cell_type":"code","source":"# This R environment comes with many helpful analytics packages installed\n# It is defined by the kaggle/rstats Docker image: https://github.com/kaggle/docker-rstats\n# For example, here's a helpful package to load\n\nlibrary(tidyverse) # metapackage of all tidyverse packages\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nlist.files(path = \"../input\")\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"── \u001b[1mAttaching packages\u001b[22m ─────────────────────────────────────── tidyverse 1.3.0 ──\n\n\u001b[32m✔\u001b[39m \u001b[34mggplot2\u001b[39m 3.3.2.\u001b[31m9000\u001b[39m     \u001b[32m✔\u001b[39m \u001b[34mpurrr  \u001b[39m 0.3.4     \n\u001b[32m✔\u001b[39m \u001b[34mtibble \u001b[39m 3.0.2          \u001b[32m✔\u001b[39m \u001b[34mdplyr  \u001b[39m 1.0.0     \n\u001b[32m✔\u001b[39m \u001b[34mtidyr  \u001b[39m 1.1.0          \u001b[32m✔\u001b[39m \u001b[34mstringr\u001b[39m 1.4.0     \n\u001b[32m✔\u001b[39m \u001b[34mreadr  \u001b[39m 1.3.1          \u001b[32m✔\u001b[39m \u001b[34mforcats\u001b[39m 0.5.0     \n\n── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n\n","name":"stderr"},{"output_type":"display_data","data":{"text/html":"'titanic'","text/markdown":"'titanic'","text/latex":"'titanic'","text/plain":"[1] \"titanic\""},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#####  Importing the training dataset and the validating dataset(without 'Target')  #####\n\n\ndata_origin <- read.csv('../input/titanic/train.csv')\ndata_train <- data_origin\ndata_validate <- read.csv('../input/titanic/test.csv')\ndata_to_clean <- list(data_train, data_validate)\ndata_to_clean_names <- list('data_train', 'data_Validate')\n\n#####  Obtaining info about datasets  #####\n\nfor (i in 1:2){\n  print(paste('Summary of the ',data_to_clean_names[i]))\n  print(summary(data.frame(data_to_clean[i])))\n}\n\n# Checking if there is any empty or 'NaN' data\nfor (dataset in data_to_clean){\n  print(data.frame(colSums(is.na(dataset) | dataset=='')))\n}\n\n#####  Replacing empty data with median and mode  #####\n\n# Creating function to find mode()\nMode <- function(x) {\n  ux <- unique(x)\n  ux[which.max(tabulate(match(x, ux)))]\n}\n\n# Dealing with training set\ndata_train$Age <- ifelse(is.na(data_train$Age) | data_train$Age=='', \n                        ave(data_train$Age, FUN = function(x) median(x, na.rm = TRUE)),\n                        data_train$Age);\ndata_train$Fare <- ifelse(is.na(data_train$Fare) | data_train$Fare=='', \n                         ave(data_train$Fare, FUN = function(x) median(x, na.rm = TRUE)),\n                         data_train$Fare); \ndata_train$Cabin <- ifelse(is.na(data_train$Cabin) | data_train$Cabin=='', \n                          0, \n                          1)\ndata_train$Embarked <- ifelse(is.na(data_train$Embarked) | data_train$Embarked=='', \n                             Mode(data_train$Embarked),\n                             data_train$Embarked)\n\n# Dealing with validating set\ndata_validate$Age <- ifelse(is.na(data_validate$Age) | data_validate$Age=='', \n                           ave(data_validate$Age, FUN = function(x) median(x, na.rm = TRUE)),\n                           data_validate$Age);\ndata_validate$Fare <- ifelse(is.na(data_validate$Fare) | data_validate$Fare=='', \n                            ave(data_validate$Fare, FUN = function(x) median(x, na.rm = TRUE)),\n                            data_validate$Fare); \ndata_validate$Cabin <- ifelse(is.na(data_validate$Cabin) | data_validate$Cabin=='', \n                            0, \n                            1)\ndata_validate$Embarked <- ifelse(is.na(data_validate$Embarked) | data_validate$Embarked=='', \n                                ode(data_validate$Embarked),\n                                data_validate$Embarked)\n\n#####  Creating 'Title' category  #####\n\npattern <- ' ([a-zA-z]{2,})\\\\. '  # Text pattern to get title from the \"Name\" column\n\n# Dealing with Training set\ndata_train$Title <- ''\nfor (i in 1:length(data_train$Name)) {\n  m <- regexpr(pattern, data_train[i,'Name'], perl=FALSE, fixed=FALSE)\n  data_train[i,'Title'] <- regmatches(data_train[i,'Name'], m)\n}\n\n# Dealing with Validating set\ndata_validate$Title <- ''\nfor (i in 1:length(data_validate$Name)) {\n  m <- regexpr(pattern, data_validate[i,'Name'], perl=FALSE, fixed=FALSE)\n  data_validate[i,'Title'] <- regmatches(data_validate[i,'Name'], m)\n}\n\n#####  Encoding Categorical data\ntitle_set <- unique(c(data_train$Title,data_validate$Title))\ntitle_labels <- seq(from = 1,to = length(title_set), by = 1)\n\ndata_to_clean <- list(data_train, data_validate)  # Collecting adjasted datasets\n\ndata_to_clean <- lapply(data_to_clean, function(df){\n  df$Title <- factor(df$Title,\n                     levels = title_set,\n                     labels = title_labels)\n  df$Sex <- factor(df$Sex,\n                   levels = c('male', 'female'),\n                   labels = c(0, 1))\n  ### return ###\n  df \n})\ndata_train <- data.frame(data_to_clean[1])  # Cleaned training data.frame\ndata_validate <- data.frame(data_to_clean[2])  # Cleaned validating data.frame\n\n##### Droping Unnecessary variables  #####\ndata_train <- subset(data_train,TRUE, select=-c(PassengerId,Name,Ticket))\ndata_validate <- subset(data_validate,TRUE, select=-c(PassengerId,Name,Ticket))\n\n##### Splitting Training dataset on train set and test set #####\nlibrary(caTools)\nset.seed(0)\nsplit = sample.split(data_train$Survived, SplitRatio = 0.8)\ntraining_set <- subset(data_train, split == TRUE)\ntest_set <- subset(data_train, split == FALSE)\n\n\n##### Feature-Scaling #####\n# Data type checking (factor data type will be ignired for scaling process)\nprint(sapply(training_set,class))\nprint(sapply(data_validate,class))\n\n# Scaling\ntraining_set[-c(1,3,10)] <- scale(training_set[-c(1,3,10)])\ntest_set[-c(1,3,10)] <- scale(test_set[-c(1,3,10)])\ndata_validate[-c(2,9)] <- scale(data_validate[-c(2,9)])\n","execution_count":2,"outputs":[{"output_type":"stream","text":"[1] \"Summary of the  data_train\"\n  PassengerId       Survived          Pclass     \n Min.   :  1.0   Min.   :0.0000   Min.   :1.000  \n 1st Qu.:223.5   1st Qu.:0.0000   1st Qu.:2.000  \n Median :446.0   Median :0.0000   Median :3.000  \n Mean   :446.0   Mean   :0.3838   Mean   :2.309  \n 3rd Qu.:668.5   3rd Qu.:1.0000   3rd Qu.:3.000  \n Max.   :891.0   Max.   :1.0000   Max.   :3.000  \n                                                 \n                                    Name         Sex           Age       \n Abbing, Mr. Anthony                  :  1   female:314   Min.   : 0.42  \n Abbott, Mr. Rossmore Edward          :  1   male  :577   1st Qu.:20.12  \n Abbott, Mrs. Stanton (Rosa Hunt)     :  1                Median :28.00  \n Abelson, Mr. Samuel                  :  1                Mean   :29.70  \n Abelson, Mrs. Samuel (Hannah Wizosky):  1                3rd Qu.:38.00  \n Adahl, Mr. Mauritz Nils Martin       :  1                Max.   :80.00  \n (Other)                              :885                NA's   :177    \n     SibSp           Parch             Ticket         Fare       \n Min.   :0.000   Min.   :0.0000   1601    :  7   Min.   :  0.00  \n 1st Qu.:0.000   1st Qu.:0.0000   347082  :  7   1st Qu.:  7.91  \n Median :0.000   Median :0.0000   CA. 2343:  7   Median : 14.45  \n Mean   :0.523   Mean   :0.3816   3101295 :  6   Mean   : 32.20  \n 3rd Qu.:1.000   3rd Qu.:0.0000   347088  :  6   3rd Qu.: 31.00  \n Max.   :8.000   Max.   :6.0000   CA 2144 :  6   Max.   :512.33  \n                                  (Other) :852                   \n         Cabin     Embarked\n            :687    :  2   \n B96 B98    :  4   C:168   \n C23 C25 C27:  4   Q: 77   \n G6         :  4   S:644   \n C22 C26    :  3           \n D          :  3           \n (Other)    :186           \n[1] \"Summary of the  data_Validate\"\n  PassengerId         Pclass     \n Min.   : 892.0   Min.   :1.000  \n 1st Qu.: 996.2   1st Qu.:1.000  \n Median :1100.5   Median :3.000  \n Mean   :1100.5   Mean   :2.266  \n 3rd Qu.:1204.8   3rd Qu.:3.000  \n Max.   :1309.0   Max.   :3.000  \n                                 \n                                        Name         Sex           Age       \n Abbott, Master. Eugene Joseph            :  1   female:152   Min.   : 0.17  \n Abelseth, Miss. Karen Marie              :  1   male  :266   1st Qu.:21.00  \n Abelseth, Mr. Olaus Jorgensen            :  1                Median :27.00  \n Abrahamsson, Mr. Abraham August Johannes :  1                Mean   :30.27  \n Abrahim, Mrs. Joseph (Sophie Halaut Easu):  1                3rd Qu.:39.00  \n Aks, Master. Philip Frank                :  1                Max.   :76.00  \n (Other)                                  :412                NA's   :86     \n     SibSp            Parch             Ticket         Fare        \n Min.   :0.0000   Min.   :0.0000   PC 17608:  5   Min.   :  0.000  \n 1st Qu.:0.0000   1st Qu.:0.0000   113503  :  4   1st Qu.:  7.896  \n Median :0.0000   Median :0.0000   CA. 2343:  4   Median : 14.454  \n Mean   :0.4474   Mean   :0.3923   16966   :  3   Mean   : 35.627  \n 3rd Qu.:1.0000   3rd Qu.:0.0000   220845  :  3   3rd Qu.: 31.500  \n Max.   :8.0000   Max.   :9.0000   347077  :  3   Max.   :512.329  \n                                   (Other) :396   NA's   :1        \n             Cabin     Embarked\n                :327   C:102   \n B57 B59 B63 B66:  3   Q: 46   \n A34            :  2   S:270   \n B45            :  2           \n C101           :  2           \n C116           :  2           \n (Other)        : 80           \n            colSums.is.na.dataset....dataset.......\nPassengerId                                       0\nSurvived                                          0\nPclass                                            0\nName                                              0\nSex                                               0\nAge                                             177\nSibSp                                             0\nParch                                             0\nTicket                                            0\nFare                                              0\nCabin                                           687\nEmbarked                                          2\n            colSums.is.na.dataset....dataset.......\nPassengerId                                       0\nPclass                                            0\nName                                              0\nSex                                               0\nAge                                              86\nSibSp                                             0\nParch                                             0\nTicket                                            0\nFare                                              1\nCabin                                           327\nEmbarked                                          0\n Survived    Pclass       Sex       Age     SibSp     Parch      Fare     Cabin \n\"integer\" \"integer\"  \"factor\" \"numeric\" \"integer\" \"integer\" \"numeric\" \"numeric\" \n Embarked     Title \n\"integer\"  \"factor\" \n   Pclass       Sex       Age     SibSp     Parch      Fare     Cabin  Embarked \n\"integer\"  \"factor\" \"numeric\" \"integer\" \"integer\" \"numeric\" \"numeric\" \"integer\" \n    Title \n \"factor\" \n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Define function\nmypack <- function(package){\n  new.package <- package[!(package %in% installed.packages()[, \"Package\"])]\n  if (length(new.package)) \n    install.packages(new.package, dependencies = TRUE)\n  sapply(package, require, character.only = TRUE)\n}\n\npackages = c('xgboost','e1071','rpart','ada','class','caret','randomForest')\nmypack(packages)","execution_count":3,"outputs":[{"output_type":"stream","text":"Loading required package: xgboost\n\n\nAttaching package: ‘xgboost’\n\n\nThe following object is masked from ‘package:dplyr’:\n\n    slice\n\n\nLoading required package: e1071\n\nLoading required package: rpart\n\nLoading required package: ada\n\nLoading required package: class\n\nLoading required package: caret\n\nLoading required package: lattice\n\n\nAttaching package: ‘caret’\n\n\nThe following object is masked from ‘package:purrr’:\n\n    lift\n\n\nThe following object is masked from ‘package:httr’:\n\n    progress\n\n\nLoading required package: randomForest\n\nrandomForest 4.6-14\n\nType rfNews() to see new features/changes/bug fixes.\n\n\nAttaching package: ‘randomForest’\n\n\nThe following object is masked from ‘package:dplyr’:\n\n    combine\n\n\nThe following object is masked from ‘package:ggplot2’:\n\n    margin\n\n\n","name":"stderr"},{"output_type":"display_data","data":{"text/html":"<style>\n.dl-inline {width: auto; margin:0; padding: 0}\n.dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n.dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n.dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n</style><dl class=dl-inline><dt>xgboost</dt><dd>TRUE</dd><dt>e1071</dt><dd>TRUE</dd><dt>rpart</dt><dd>TRUE</dd><dt>ada</dt><dd>TRUE</dd><dt>class</dt><dd>TRUE</dd><dt>caret</dt><dd>TRUE</dd><dt>randomForest</dt><dd>TRUE</dd></dl>\n","text/markdown":"xgboost\n:   TRUEe1071\n:   TRUErpart\n:   TRUEada\n:   TRUEclass\n:   TRUEcaret\n:   TRUErandomForest\n:   TRUE\n\n","text/latex":"\\begin{description*}\n\\item[xgboost] TRUE\n\\item[e1071] TRUE\n\\item[rpart] TRUE\n\\item[ada] TRUE\n\\item[class] TRUE\n\\item[caret] TRUE\n\\item[randomForest] TRUE\n\\end{description*}\n","text/plain":"     xgboost        e1071        rpart          ada        class        caret \n        TRUE         TRUE         TRUE         TRUE         TRUE         TRUE \nrandomForest \n        TRUE "},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"##########  Machine Learning Algorithm (MLA) Selection  ##########\n#install.packages('Boruta', repos=\"https://cran.rstudio.com/\",type = \"source\") ##only for first time run the script\nlibrary(xgboost)\nlibrary(e1071)\nlibrary(rpart)\nlibrary(ada)\nlibrary(class)\nlibrary(caret)\nlibrary(randomForest)\n\n# Creating data.frame(\"MLA\",\"Accuracy\") for collecting the results of the predictions\nMLA_accuracy <- data.frame(MLA = character(), Accuracy = double(),stringsAsFactors=FALSE)\ny_test <- as.factor(test_set$Survived)  # Need factor format for confusionMatrix() function\n\n# Checking if all Features are independent and necessary\nlibrary(Boruta)\nglm_boruta <- Boruta(Survived ~.,data = training_set, doTrace=0)\nroughFixMod <- TentativeRoughFix(glm_boruta)\nprint(attStats(roughFixMod)[order(-attStats(roughFixMod)$meanImp),])  # Descending order by meanImp\n\n# Logistic Regression\nclass_glm <- glm(formula = Survived ~.,\n                family = binomial,\n                data = training_set)\np_pred_glm <- predict(class_glm, type = 'response', newdata = test_set[-1])\ny_pred_glm <- ifelse(p_pred_glm > 0.5, 1, 0)\ny_pred_glm <- as.factor(y_pred_glm)\ncm_glm <- confusionMatrix(y_pred_glm, y_test)\nMLA_accuracy[nrow(MLA_accuracy)+1,] <- list('LogReg',cm_glm$overall['Accuracy'])  # To \"MLA-Accuracy\"\n\n# XGBoost\nclass_xgb <- xgboost(data = as.matrix(sapply(training_set[-1],as.numeric)), \n                    label = as.numeric(training_set$Survived),\n                    nrounds = 10)\ny_pred_xgb <- predict(class_xgb, newdata = as.matrix(sapply(test_set[-1],as.numeric)))\ny_pred_xgb <- ifelse(y_pred_xgb>=0.5, 1, 0)\ny_pred_xgb <- as.factor(y_pred_xgb)\ncm_xgb <- confusionMatrix(y_pred_xgb,y_test)\nMLA_accuracy[nrow(MLA_accuracy)+1,] <- list('XGBoost',cm_xgb$overall['Accuracy'])  # To \"MLA-Accuracy\"\n\n# SVM\nclass_svm <- svm(formula = Survived ~.,\n                data = training_set,\n                type = 'C-classification')\ny_pred_svm <- predict(class_svm, newdata = test_set[-1])\ny_pred_svm <- as.factor(y_pred_svm)\ncm_svm = confusionMatrix(y_pred_svm, y_test)\nMLA_accuracy[nrow(MLA_accuracy)+1,] <- list('SVM',cm_svm$overall['Accuracy'])  # To \"MLA-Accuracy\"\n\n# Naive Bayes\nclass_nb <- naiveBayes(as.factor(Survived) ~ .,\n                      training_set)\ny_pred_nb <- predict(class_nb, as.data.frame(test_set[-1]), type='class')\ncm_nb <- confusionMatrix(y_pred_nb,y_test)\nMLA_accuracy[nrow(MLA_accuracy)+1,] <- list('NB',cm_nb$overall['Accuracy'])  # To \"MLA-Accuracy\"\n\n# Decision Trees(CART)\nclass_dtree <- rpart(formula = Survived ~.,\n                    data = training_set,\n                    method = 'class')\ny_pred_dtree <- predict(class_dtree, newdata = test_set[-1], type='class')\ncm_dtree <- confusionMatrix(y_pred_dtree,y_test)\nMLA_accuracy[nrow(MLA_accuracy)+1,] <- list('DTree',cm_dtree$overall['Accuracy'])  # To \"MLA-Accuracy\"\n\n# AdaBoost\nclass_ada <- ada(formula = Survived ~.,\n            data = training_set)\ny_pred_ada <- predict(class_ada, newdata = test_set[-1])\ncm_ada <- confusionMatrix(y_pred_ada,y_test)\nMLA_accuracy[nrow(MLA_accuracy)+1,] <- list('ADA',cm_ada$overall['Accuracy'])  # To \"MLA-Accuracy\"\n\n# KNN\ny_pred_knn <- knn(train = training_set[,-1],\n                 test = test_set[,-1], \n                 cl = training_set[,1],\n                 k = 5)\ncm_knn <- confusionMatrix(y_pred_knn,y_test)\nMLA_accuracy[nrow(MLA_accuracy)+1,] <- list('KNN',cm_knn$overall['Accuracy'])  # To \"MLA-Accuracy\"\n\n# Random Forest\nclass_rforest <- randomForest(formula = Survived ~.,\n                             data = training_set,\n                             ntree = 100)\ny_pred_rforest <- predict(class_rforest, newdata = test_set, type = 'response')\ny_pred_rforest <- as.factor(ifelse(y_pred_rforest>0.5, 1, 0))\ncm_rforest <- confusionMatrix(y_pred_rforest,y_test)\nMLA_accuracy[nrow(MLA_accuracy)+1,] <- list('RForest',cm_rforest$overall['Accuracy'])  # To \"MLA-Accuracy\"\n\n# Accuracy results:\nprint(\"MLA Accuracy Results:\")\nprint(MLA_accuracy[order(-MLA_accuracy$Accuracy), ])","execution_count":4,"outputs":[{"output_type":"stream","text":"Warning message in TentativeRoughFix(glm_boruta):\n“There are no Tentative attributes! Returning original object.”\n","name":"stderr"},{"output_type":"stream","text":"           meanImp medianImp    minImp    maxImp normHits  decision\nSex      29.973448 29.899924 28.681728 32.792260        1 Confirmed\nPclass   29.014857 29.095628 26.398744 31.593829        1 Confirmed\nTitle    26.586996 26.388754 25.149277 29.036027        1 Confirmed\nFare     25.003639 25.213584 23.566298 25.916207        1 Confirmed\nSibSp    15.663664 15.983752 13.147619 17.254656        1 Confirmed\nAge      14.916491 14.864870 12.581940 17.811070        1 Confirmed\nCabin    14.410920 13.866709 12.522547 17.726039        1 Confirmed\nEmbarked  9.633698  9.351308  6.862977 12.679042        1 Confirmed\nParch     6.798006  6.556574  5.416862  7.870987        1 Confirmed\n[1]\ttrain-rmse:0.411122 \n[2]\ttrain-rmse:0.356199 \n[3]\ttrain-rmse:0.316868 \n[4]\ttrain-rmse:0.292126 \n[5]\ttrain-rmse:0.278784 \n[6]\ttrain-rmse:0.271560 \n[7]\ttrain-rmse:0.259003 \n[8]\ttrain-rmse:0.244513 \n[9]\ttrain-rmse:0.240038 \n[10]\ttrain-rmse:0.233490 \n","name":"stdout"},{"output_type":"stream","text":"Warning message in randomForest.default(m, y, ...):\n“The response has five or fewer unique values.  Are you sure you want to do regression?”\n","name":"stderr"},{"output_type":"stream","text":"[1] \"MLA Accuracy Results:\"\n      MLA  Accuracy\n6     ADA 0.7865169\n1  LogReg 0.7696629\n5   DTree 0.7584270\n3     SVM 0.7528090\n8 RForest 0.7528090\n7     KNN 0.7471910\n2 XGBoost 0.7359551\n4      NB 0.7359551\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Too heavy for a fast run on Kaggle's CPUs\n\n\n# Tunning the MLA parameters \nfitControl = trainControl(\n  method = 'LOOCV',\n  number = 5,\n  #repeats = 10,\n  savePredictions = 'all',\n  #classProbs = TRUE\n)\nTrainData <- training_set\nTrainData$Title <- make.names(TrainData$Title)\nTrainData$Sex <- make.names(TrainData$Sex)\nTrainData$Survived <- make.names(TrainData$Survived)\n\ngmbGrid = expand.grid(\n  iter = c(45,50,55),\n  nu=0.1,\n  maxdepth = c(2,3,4,5)\n)\n\n#ML_methods = c('ada', 'xgbLinear')\n\ngbmFit1 <- train(Survived~., TrainData, \n                 method = 'ada', \n                 trControl = fitControl\n                 ## This last option is actually one\n                 ## for gbm() that passes through\n                 #verbose = FALSE\n                 #tuneGrid = gmbGrid\n                 )\n\ngbmFit1\n\n\n","execution_count":11,"outputs":[{"output_type":"error","ename":"ERROR","evalue":"Error in parse(text = x, srcfile = src): <text>:3:3: unexpected INCOMPLETE_STRING\n35: \n36: \n      ^\n","traceback":["Error in parse(text = x, srcfile = src): <text>:3:3: unexpected INCOMPLETE_STRING\n35: \n36: \n      ^\nTraceback:\n"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Next we'll need to try Yandex's ML product - Catboost","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"3.6.3"}},"nbformat":4,"nbformat_minor":1}